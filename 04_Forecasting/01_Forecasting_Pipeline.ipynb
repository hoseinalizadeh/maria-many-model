{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasting Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we create a pipeline for Forcasting 11,973 ARIMA models. The training and scoring of these models was completed in the Training and Scoring notebooks in this repository. We will set up the Pipeline for forecasting given the desired forecasting horizon. We utitlize the [ParallelRunStep](https://docs.microsoft.com/en-us/python/api/azureml-contrib-pipeline-steps/azureml.contrib.pipeline.steps.parallel_run_step.parallelrunstep?view=azure-ml-py) to parallelize the process. For more information about the Data and Models refer to the Data Preparation and Training Notebooks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prerequisites \n",
    "\n",
    "This example runs on an Azure Machine Learning Notebook VM. We are calling models that have **already been trained and registered** to the Workspace. If you have already run the Environment Setup and Training Pipeline notebooks or you have an AML Notebook set up with Models registered to the Workspace you are all set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call the Workspace, Datastore, and Compute\n",
    "\n",
    "As we did in the Training Pipeline notebook, we need to call the Workspace. We also want to create variables for the datastore and compute cluster. \n",
    "\n",
    "### Connect to the workspace\n",
    "Create a workspace object. *Workspace.from_config()* reads the config.json file and loads the details into an object named ws. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace \n",
    "\n",
    "# ws = Workspace(subscription_id=\"bbd86e7d-3602-4e6d-baa4-40ae2ad9303c\", resource_group=\"ManyModelsSA\", workspace_name=\"ManyModelsSAv1\")\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attach existing compute resource\n",
    "From the Environment Setup Notebook, we created a compute cluster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import AmlCompute, ComputeTarget\n",
    "\n",
    "compute = AmlCompute(ws, 'train-many-model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call the Datastore containing the Orange Juice sales data\n",
    "From the Data Preparation Notebook, we uploaded the csv's for each Store and Brand comination. Use *.get_default_datastore()* to save the datastore we uploaded the files into. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dstore = ws.get_default_datastore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call Registered FileDataset\n",
    "In the Data Preparation notebook, we uploaded our data to Blob storage then registered the folder of data as a FileDataset to the Workspace. We are call that Dataset in order to pass it as an input into our ParallelRunStep. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.dataset import Dataset\n",
    "\n",
    "FileDst10Models = Dataset.get_by_name(ws, name='10modelsfiledataset')\n",
    "FileDst10ModelsInput = FileDst10Models.as_named_input('Train10Models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.dataset import Dataset\n",
    "\n",
    "FileDstAllModels = Dataset.get_by_name(ws, name='AllDataProd')\n",
    "FileDstAllModelsInputs = FileDstAllModels.as_named_input('ForecastAllmodels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from azureml.core.dataset import Dataset\n",
    "\n",
    "# ds_name = 'AllDataProd'\n",
    "# oj_ds = Dataset.get_by_name(ws, name = ds_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subset the number of models to run\n",
    "If you would like to test the forecasting pipeline with a subset of models use the following code to take a sample of the full dataset. To make sure the same subset is selected across the Training, Scoring and Forecasting Notebooks use the same seed value. The *take_sample* function is taking a random sample. Otherwise, run the commented out line to run all 11,000+ models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Subset to 14 models\n",
    "# oj_ds_subset = oj_ds.take_sample(0.001, seed = 1248) \n",
    "\n",
    "# # Subset to 50 models\n",
    "# #oj_ds_subset = oj_ds.take_sample(0.005, seed = 1248)\n",
    "\n",
    "# # subset to 1,000 models \n",
    "# #oj_ds_subset = oj_ds.take_sample(0.084, seed = 1248)\n",
    "\n",
    "# oj_input_data = oj_ds_subset.as_named_input('oj_series')\n",
    "\n",
    "# # This line will create a dataset for the full 11,973 models. \n",
    "# #oj_input_data = oj_ds.as_named_input('oj_series')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create entry script for Forecasting\n",
    "To use the models to make forecasts, you need an **entry script** and a list of **dependencies**:\n",
    "\n",
    "#### An entry script\n",
    "This script accepts requests, scores the requests by using the model, and returns the results.\n",
    "- __init()__ - Typically this function loads the model into a global object. This function is run only once at the start of batch processing per worker node/process. init method can make use of following environment variables (ParallelRunStep input):\n",
    "    \tAZUREML_BI_OUTPUT_PATH â€“ output folder path\n",
    "    \n",
    "    \n",
    "    \n",
    "- __run(mini_batch)__ - The method to be parallelized. Each invocation will have one minibatch.<BR>\n",
    "\n",
    "    - __mini_batch__: Batch inference will invoke run method and pass either a list or Pandas DataFrame as an argument to the method. Each entry in mini_batch will be - a filepath if input is a FileDataset, a Pandas DataFrame if input is a TabularDataset.<BR>\n",
    "\n",
    "    - __run__ method response: run() method should return a Pandas DataFrame or an array. For append_row output_action, these returned elements are appended into the common output file. For summary_only, the contents of the elements are ignored. For all output actions, each returned output element indicates one successful inference of input element in the input mini-batch.\n",
    "    The User should make sure that enough data is included in inference result to map input to inference. Inference output will be written in output file and not guaranteed to be in order, the user should use some key in the output to map it to input.\n",
    "    \n",
    "\n",
    "#### Dependencies\n",
    "Helper scripts or Python/Conda packages are required to run the entry script or model.\n",
    "\n",
    "The deployment configuration for the compute target that hosts the deployed model. This configuration describes things like memory and CPU requirements needed to run the model.\n",
    "\n",
    "These items are encapsulated into an inference configuration and a deployment configuration. The inference configuration references the entry script and other dependencies. You define these configurations programmatically when you use the SDK to perform the deployment. You define them in JSON files when you use the CLI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and Run the batch inferece pipeline\n",
    "Now that the data, models, and compute resources are set up, we can put together a pipeline for forecasting. \n",
    "### Set up the environment to run the script\n",
    "Specify the conda dependencies for your script. This will allow us to install packages and configure the environment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "from azureml.core.runconfig import DEFAULT_CPU_IMAGE\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "# set up the batch environment settings\n",
    "batch_conda_deps = CondaDependencies.create(pip_packages=['sklearn','pmdarima'])\n",
    "\n",
    "batch_env = Environment(name=\"manymodels_environment\")\n",
    "batch_env.python.conda_dependencies = batch_conda_deps\n",
    "batch_env.docker.enabled = True\n",
    "batch_env.docker.base_image = DEFAULT_CPU_IMAGE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the configuration to wrap the inference script \n",
    "In the [ParallelRunConfig](https://docs.microsoft.com/en-us/python/api/azureml-contrib-pipeline-steps/azureml.contrib.pipeline.steps.parallelrunconfig?view=azure-ml-py), we will call the entry script, environment configuration, and parameters. You will want to determine the number of workers and nodes appropriate for your use case.\n",
    "- The **workercount** is based off the number of cores on the VM. The compute cluster we set up has 8 cores therefore we set our worker count to 8.  \n",
    "- The**nodecount** will determine the number of nodes to use. Increasing the node count should help to speed up the process. We started with 3 then increased the number in order for the job to complete in under an hour. \n",
    "- You should set the **timeout** to be the slightly longer than amount of time it would take for one iteration of your script to complete. In this example, that would be the amount of time to pull down a model and make predictions. The default time is 60 seconds. \n",
    "\n",
    "**include info here about runs we tried**\n",
    "\n",
    "We added tags for additional information about our settings for the step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.contrib.pipeline.steps import ParallelRunStep, ParallelRunConfig \n",
    "\n",
    "workercount = 8\n",
    "nodecount = 5\n",
    "timeout = 500\n",
    "\n",
    "tags1 = {}\n",
    "tags1['nodes'] = nodecount\n",
    "tags1['workers-per-node'] = workercount\n",
    "tags1['timeout'] = timeout \n",
    "\n",
    "parallel_run_config = ParallelRunConfig(\n",
    "    source_directory = './scripts',\n",
    "    entry_script = 'forecast.py',\n",
    "    mini_batch_size = '1',\n",
    "    run_invocation_timeout = timeout, \n",
    "    error_threshold = 10,\n",
    "    output_action = 'append_row', \n",
    "    environment = batch_env, \n",
    "    process_count_per_node = workercount, \n",
    "    compute_target = compute, \n",
    "    node_count = nodecount\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the ParallelRunStep\n",
    " This [ParallelRunStep](https://docs.microsoft.com/en-us/python/api/azureml-contrib-pipeline-steps/azureml.contrib.pipeline.steps.parallel_run_step.parallelrunstep?view=azure-ml-py) is the main step in our pipeline.  \n",
    "\n",
    "We can specified the following parameters: \n",
    "- **input** : We will provide the data that will be used in the entry_script. \n",
    "- **output** : This is the directory where the output of the step will be written. \n",
    "- **models** : This provides additional metadata about the models used in the step. \n",
    "- **arguments** : You can specify arguments that you want to pass to the entry_script with this argument.\n",
    "\n",
    "*arguments* and *inputs* are the two parameters that can pass information to the entry_script.\n",
    "\n",
    "We also need to specify an output directory. This is where output from the setp will be stored. \n",
    "\n",
    "#### For the orange juice sales forecasting, we have two arguments passed to the entry_script. \n",
    "- **forecast_horizon** is how far into the future the forecast should extend.\n",
    "- **starting_date** is the date to begin forecating. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core import PipelineData\n",
    "\n",
    "datasetname = 'store'\n",
    "output_dir = PipelineData(name = 'forecasting_output', \n",
    "                         datastore = dstore)\n",
    "\n",
    "parallelrun_step = ParallelRunStep(\n",
    "    name=\"many-models-forecasting\",\n",
    "    parallel_run_config=parallel_run_config,\n",
    "    inputs=[FileDstAllModelsInputs],  \n",
    "    output=output_dir,\n",
    "    models= [], # this is just for logging\n",
    "    arguments=['--forecast_horizon', 8,\n",
    "              '--starting_date', '1992-10-01',\n",
    "              '--output_datastore', 'forecasting_output_datastore',\n",
    "              '--overwrite_forecasting', True],\n",
    "    allow_reuse = False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up RunConfiguration for PythonScriptStep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.core.runconfig import CondaDependencies\n",
    "\n",
    "conda_run_config = RunConfiguration(framework=\"python\")\n",
    "conda_run_config.target = compute\n",
    "conda_run_config.environment.docker.enabled = True\n",
    "conda_run_config.environment.docker.base_image = DEFAULT_CPU_IMAGE\n",
    "cd = CondaDependencies.create(pip_packages=['azureml-pipeline-core'], conda_packages=['pandas'])\n",
    "conda_run_config.environment.python.conda_dependencies = cd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up PythonScriptStep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "\n",
    "log_python_script_step = PythonScriptStep(name=\"logging\",\n",
    "                        script_name=\"log.py\",\n",
    "                        compute_target=compute,\n",
    "                        source_directory='./scripts',\n",
    "                        runconfig=conda_run_config,\n",
    "                        arguments=['--ParallelRunStep_name','many-models-forecasting', '--pipeline_output_name', 'forecasting_output', '--datastore', 'forecasting_output_datastore', '--experiment', 'automl-ojforecasting', '--overwrite_logs', True],\n",
    "                        allow_reuse=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the step sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core import StepSequence\n",
    "\n",
    "all_steps = StepSequence(steps=[parallelrun_step, log_python_script_step])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit and Run the Pipeline\n",
    "Create an Experiment to track the runs of the pipeline. Then, you can run the pipeline and review the output. With the current settings and the Standard_D13_V2 VM the pipeline takes approximately 1h 5m to run forecasts for all 11,973 models.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the experiment\n",
    "from azureml.core import Experiment\n",
    "from azureml.pipeline.core import Pipeline\n",
    "\n",
    "experiment = Experiment(ws, 'automl-ojforecasting')\n",
    "\n",
    "pipeline = Pipeline(workspace = ws, steps=[all_steps])\n",
    "\n",
    "run = experiment.submit(pipeline, tags=tags1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Succesfully forecasted and logged 11,973 models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Publish the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After a succesful run, we publish the pipeline to the Workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "published_pipeline = pipeline.publish(name = 'forecast-all-models',\n",
    "                                     description = 'forecast 11,973 models and log the run',\n",
    "                                     version = '1',\n",
    "                                     continue_on_step_failure = True\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schedule the pipeline to run weekly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A published pipeline represents a Pipeline to be submitted without the Python code which constructed it.\n",
    "\n",
    "In addition, a [PublishedPipeline](https://docs.microsoft.com/en-us/python/api/azureml-pipeline-core/azureml.pipeline.core.publishedpipeline?view=azure-ml-py) can be used to resubmit a Pipeline with different PipelineParameter values and inputs. The following code block will retrieve all the published pipelines in the Workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core import PublishedPipeline\n",
    "\n",
    "published_pipelines = PublishedPipeline.list(ws)\n",
    "for published_pipeline in  published_pipelines:\n",
    "    print(f\"{published_pipeline.name},'{published_pipeline.id}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we identify the pipeline_id of the just published pipline. We can schedule this piepline to a desired cadence. In this case, we schedule the Pipeline to run on the first day of every month starting Jan 1, 2020 at 1PM UTC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core import Schedule, ScheduleRecurrence\n",
    "    \n",
    "forecast_pipeline_id = 'c0fa9dce-441d-450b-93a6-3d2afccc3036'\n",
    "\n",
    "recurrence = ScheduleRecurrence(frequency=\"Week\", interval=1, start_time=\"2020-01-01T13:00:00\")\n",
    "recurring_schedule = Schedule.create(ws, name=\"Forecasting-Pipeline-Recurring-Schedule\", \n",
    "                            description=\"Schedule forecasting Pipeline to run on the first day of every month starting Jan 1, 2020 at 1PM\",\n",
    "                            pipeline_id=forecast_pipeline_id, \n",
    "                            experiment_name=experiment.name, \n",
    "                            recurrence=recurrence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
