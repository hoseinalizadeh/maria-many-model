{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "\n",
    "# set up workspace\n",
    "ws = Workspace.from_config()\n",
    "\n",
    "# Take a look at Workspace\n",
    "ws.get_details()\n",
    "\n",
    "# set up datastores\n",
    "dstore = ws.get_default_datastore()\n",
    "\n",
    "print('Workspace Name: ' + ws.name, \n",
    "      'Azure Region: ' + ws.location, \n",
    "      'Subscription Id: ' + ws.subscription_id, \n",
    "      'Resource Group: ' + ws.resource_group, \n",
    "      sep = '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "\n",
    "experiment = Experiment(ws, 'training-pipeline')\n",
    "\n",
    "print('Experiment name: ' + experiment.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from azureml.core.dataset import Dataset\n",
    "\n",
    "small_dataset = Dataset.get_by_name(ws, name='oj_data_small')\n",
    "small_dataset_input = small_dataset.as_named_input('train_10_models')\n",
    "\n",
    "#dataset = Dataset.get_by_name(ws, name='oj_data')\n",
    "#dataset_input = dataset.as_named_input('train_all_models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "train_env = Environment(name=\"many_models_environment\")\n",
    "train_conda_deps = CondaDependencies.create(pip_packages=['sklearn', 'pmdarima'])\n",
    "train_env.python.conda_dependencies = train_conda_deps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from azureml.core.compute import AmlCompute\n",
    "\n",
    "compute = AmlCompute(ws, \"train-many-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from azureml.contrib.pipeline.steps import ParallelRunConfig\n",
    "\n",
    "worker_count = 8\n",
    "node_count = 5\n",
    "timeout = 500\n",
    "\n",
    "datasetname='stores_filedatasets'\n",
    "\n",
    "tags = {}\n",
    "tags['DatasetName'] = datasetname\n",
    "tags['Nodes'] = node_count\n",
    "tags['WorkersPerNode'] = worker_count\n",
    "tags['Timeout'] = timeout\n",
    "\n",
    "parallel_run_config = ParallelRunConfig(\n",
    "    source_directory='./scripts',\n",
    "    entry_script='train.py',\n",
    "    mini_batch_size=\"1\",\n",
    "    run_invocation_timeout=timeout,\n",
    "    error_threshold=10,\n",
    "    output_action=\"append_row\",\n",
    "    environment=train_env,\n",
    "    process_count_per_node=worker_count,\n",
    "    compute_target=compute,\n",
    "    node_count=node_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from azureml.pipeline.core import PipelineData\n",
    "\n",
    "output_dir = PipelineData(name=\"training_output\", \n",
    "                          datastore=dstore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from azureml.contrib.pipeline.steps import ParallelRunStep\n",
    "\n",
    "parallel_run_step = ParallelRunStep(\n",
    "    name=\"many-models-training\",\n",
    "    parallel_run_config=parallel_run_config,\n",
    "    inputs=[small_dataset_input], # train 10 models\n",
    "#     inputs=[dataset_input], # switch to this inputs if train all 11,973 models\n",
    "    output=output_dir,\n",
    "    models=[],\n",
    "    arguments=['--target_column', 'Quantity', \n",
    "               '--n_test_periods', 6, \n",
    "               '--timestamp_column', 'WeekStarting', \n",
    "               '--stepwise_training', True])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the PythonScriptStep\n",
    "\n",
    "We then set up a PythonScriptStep to retrieve the output of the training pipeline (in this case, a file with trained models' logging information) and upload it to a dedicated blob path.\n",
    "\n",
    "### Set up RunConfiguration for PythonScriptStep\n",
    "\n",
    "Run configuration represents configuration for experiment runs targeting different compute targets in Azure Machine Learning. The RunConfiguration object encapsulates the information necessary to submit a training run in an experiment. Here we define azureml-pipeline-core and Pandas packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.core.runconfig import CondaDependencies\n",
    "\n",
    "run_config = RunConfiguration(framework=\"python\")\n",
    "run_config.target = compute\n",
    "cd = CondaDependencies.create(pip_packages=['azureml-pipeline-core'], conda_packages=['pandas'])\n",
    "run_config.environment.python.conda_dependencies = cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "\n",
    "script_step = PythonScriptStep(name=\"logging\",\n",
    "                        script_name=\"log.py\",\n",
    "                        compute_target=compute,\n",
    "                        source_directory='./scripts',\n",
    "                        runconfig=run_config,\n",
    "                        arguments=['--parallelrunstep_name', parallel_run_step.name,\n",
    "                                   '--datastore', dstore.name, \n",
    "                                   '--experiment', experiment.name, \n",
    "                                   '--overwrite_logs', True, \n",
    "                                   '--pipeline_output_name', output_dir.name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from azureml.pipeline.core import StepSequence\n",
    "\n",
    "training_steps = StepSequence(steps=[parallel_run_step, script_step])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from azureml.pipeline.core import Pipeline\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "pipeline = Pipeline(workspace=ws, steps=training_steps)\n",
    "run = experiment.submit(pipeline,tags=tags)\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "published_pipeline = pipeline.publish(name = 'train_many_models',\n",
    "                                     description = 'train many models and log the run',\n",
    "                                     version = '1',\n",
    "                                     continue_on_step_failure = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from azureml.pipeline.core import Schedule, ScheduleRecurrence\n",
    "    \n",
    "training_pipeline_id = published_pipeline.id\n",
    "\n",
    "recurrence = ScheduleRecurrence(frequency=\"Month\", interval=1, start_time=\"2020-01-01T09:00:00\")\n",
    "recurring_schedule = Schedule.create(ws, name=\"training_pipeline_recurring_schedule\", \n",
    "                            description=\"Schedule Training Pipeline to run on the first day of every month starting Jan 1, 2020 at 9AM\",\n",
    "                            pipeline_id=training_pipeline_id, \n",
    "                            experiment_name=experiment.name, \n",
    "                            recurrence=recurrence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
