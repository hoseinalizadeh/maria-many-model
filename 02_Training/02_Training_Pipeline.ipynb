{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Pipeline\n",
    "\n",
    "We do this using a 'pipeline first mentality' i.e. we want to have a production pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace, Dataset, Experiment\n",
    "from azureml.core.runconfig import RunConfiguration, DEFAULT_CPU_IMAGE, CondaDependencies\n",
    "from azureml.core.compute import AmlCompute\n",
    "from azureml.pipeline.core import Pipeline, PipelineDataset, PipelineParameter, PipelineData, TrainingOutput, Schedule\n",
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "from azureml.train.automl import AutoMLStep, AutoMLConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up workspace, experiment and compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = Workspace.from_config()\n",
    "dstor = ws.datastores[\"workspaceblobstore\"]\n",
    "ds_name = \"AirliftDataset-Train\"\n",
    "experiment = Experiment(ws, \"airlift\")\n",
    "aml_compute_target = AmlCompute(ws, \"onenode-cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up Run Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda_run_config = RunConfiguration(framework=\"python\")\n",
    "conda_run_config.target = aml_compute_target\n",
    "conda_run_config.environment.docker.enabled = True\n",
    "conda_run_config.environment.docker.base_image = DEFAULT_CPU_IMAGE\n",
    "cd = CondaDependencies.create(pip_packages=[\"azureml-sdk[automl]\", \"scikit-learn\", \"azureml-explain-model\"], conda_packages=[\"numpy\"])\n",
    "conda_run_config.environment.python.conda_dependencies = cd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Training Data Step\n",
    "\n",
    "We need to bring the data into a common X, y format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_name = PipelineParameter(\"column_name\", default_value=\"BOUGHT_CATEGORY_10\")\n",
    "output_split_train_x = PipelineData(\"output_split_train_x\", datastore=dstor)\n",
    "output_split_train_y = PipelineData(\"output_split_train_y\", datastore=dstor)\n",
    "output_split_test_x = PipelineData(\"output_split_test_x\", datastore=dstor)\n",
    "output_split_test_y = PipelineData(\"output_split_test_y\", datastore=dstor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_train_split_step = PythonScriptStep(script_name=\"train_test_split.py\", \n",
    "                                         allow_reuse=True,\n",
    "                                         name=\"test_train_split_step\",\n",
    "                                         arguments=[\"--target_column\", target_name,\n",
    "                                                       \"--input_dataset\", ds_name,\n",
    "                                                       \"--output_split_train_x\", output_split_train_x,\n",
    "                                                       \"--output_split_train_y\", output_split_train_y,\n",
    "                                                       \"--output_split_test_x\", output_split_test_x,\n",
    "                                                       \"--output_split_test_y\", output_split_test_y],\n",
    "                                         outputs=[output_split_train_x, output_split_train_y, output_split_test_x, output_split_test_y], \n",
    "                                         compute_target=aml_compute_target, \n",
    "                                         runconfig=conda_run_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Environment variable of X train split: \" + output_split_train_x.__str__())\n",
    "print(\"Environment variable of y train split: \" + output_split_train_y.__str__())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoML Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_data = PipelineData(name=\"automl_metrics\",\n",
    "                            datastore=dstor, \n",
    "                            pipeline_output_name=\"metrics_output\",\n",
    "                            training_output=TrainingOutput(type=\"Metrics\"))\n",
    "\n",
    "model_data = PipelineData(name=\"automl_model\", \n",
    "                          datastore=dstor,\n",
    "                          pipeline_output_name=\"best_model_output\",\n",
    "                          training_output=TrainingOutput(type=\"Model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_config = AutoMLConfig(task = \"classification\",\n",
    "                             iterations = 1,\n",
    "                             iteration_timeout_minutes = 5, \n",
    "                             max_cores_per_iteration = 4,\n",
    "                             max_concurrent_iterations = 1,\n",
    "                             primary_metric = \"accuracy\",\n",
    "                             path=\".\",\n",
    "                             data_script = \"get_data.py\",\n",
    "                             run_configuration = conda_run_config,\n",
    "                             model_explainability = True,\n",
    "                             n_cross_validations = 2,\n",
    "                             preprocess = True,\n",
    "                             compute_target=aml_compute_target)\n",
    "\n",
    "automl_step = AutoMLStep(name=\"build_model\", \n",
    "                         allow_reuse=True,\n",
    "                         automl_config=automl_config,\n",
    "                         inputs=[output_split_train_x, output_split_train_y],\n",
    "                         outputs=[metrics_data, model_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register Model Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "register_model_step = PythonScriptStep(script_name=\"register_model.py\",\n",
    "                                       name=\"register_model\",\n",
    "                                       allow_reuse=True,\n",
    "                                       arguments=[\"--model_id\", target_name, \"--model_path\", model_data, \"--ds_name\", ds_name],\n",
    "                                       inputs=[model_data],\n",
    "                                       compute_target=aml_compute_target,\n",
    "                                       runconfig=conda_run_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create pipeline object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(ws, steps=[test_train_split_step, automl_step, register_model_step])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_run = experiment.submit(pipeline, pipeline_params={\"column_name\": \"BOUGHT_CATEGORY_3\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schedule the pipeline on a blob change "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Publish pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_name = \"Prop-Training-Pipeline\"\n",
    "print(pipeline_name)\n",
    "\n",
    "published_pipeline = pipeline.publish(\n",
    "    name=pipeline_name, \n",
    "    description=pipeline_name)\n",
    "\n",
    "print(\"Newly published pipeline id: {}\".format(published_pipeline.id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schedule all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = [\"BOUGHT_CATEGORY_\" + str(i) for i in range(1,11)]\n",
    "model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in model_list:\n",
    "    schedule = Schedule.create(workspace=ws, name=m,\n",
    "                               pipeline_parameters={\"column_name\": m},\n",
    "                               pipeline_id=published_pipeline.id, \n",
    "                               experiment_name=m, # this creates parallelism on an AML cluster\n",
    "                               datastore=dstor,\n",
    "                               wait_for_provisioning=True,\n",
    "                               description=m,\n",
    "                               polling_interval=1440,\n",
    "                               path_on_datastore=\"airlift/data-latest.csv\")\n",
    "\n",
    "    print(\"Created schedule with id: {}\".format(schedule.id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Disable schedules as this is a demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in Schedule.list(ws):\n",
    "    s.disable()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
