{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK version: 1.0.74\n"
     ]
    }
   ],
   "source": [
    "#import stuff and get workspace\n",
    "import os\n",
    "import azureml.core\n",
    "from azureml.core import Workspace, Experiment, Run\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.runconfig import DEFAULT_CPU_IMAGE\n",
    "from azureml.pipeline.core import Pipeline\n",
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "from azureml.widgets import RunDetails\n",
    "from azureml.core import Workspace, Experiment, Datastore\n",
    "from azureml.core.compute import AmlCompute\n",
    "from azureml.core.compute import ComputeTarget\n",
    "from azureml.widgets import RunDetails\n",
    "from azureml.data.data_reference import DataReference\n",
    "from azureml.pipeline.core import Pipeline, PipelineData\n",
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "from azureml.pipeline.core.schedule import ScheduleRecurrence, Schedule\n",
    "from azureml.core.dataset import Dataset\n",
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "\n",
    "\n",
    "print(\"SDK version:\", azureml.core.VERSION)\n",
    "#auth = InteractiveLoginAuthentication(force=True, tenant_id=\"72f988bf-86f1-41af-91ab-2d7cd011db47\")\n",
    "# ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '/subscriptions/bbd86e7d-3602-4e6d-baa4-40ae2ad9303c/resourceGroups/ManyModelsSA/providers/Microsoft.MachineLearningServices/workspaces/ManyModelsSAv1',\n",
       " 'name': 'ManyModelsSAv1',\n",
       " 'location': 'centralus',\n",
       " 'type': 'Microsoft.MachineLearningServices/workspaces',\n",
       " 'tags': {},\n",
       " 'sku': 'Enterprise',\n",
       " 'workspaceid': '77752be6-01b4-4a3e-9d42-03c9c0d6248f',\n",
       " 'description': '',\n",
       " 'friendlyName': '',\n",
       " 'creationTime': '2019-11-18T20:17:22.9729795+00:00',\n",
       " 'containerRegistry': '/subscriptions/bbd86e7d-3602-4e6d-baa4-40ae2ad9303c/resourceGroups/ManyModelsSA/providers/Microsoft.ContainerRegistry/registries/manymodelssa8faf85d6',\n",
       " 'keyVault': '/subscriptions/bbd86e7d-3602-4e6d-baa4-40ae2ad9303c/resourcegroups/manymodelssa/providers/microsoft.keyvault/vaults/manymodelssav16798764194',\n",
       " 'applicationInsights': '/subscriptions/bbd86e7d-3602-4e6d-baa4-40ae2ad9303c/resourcegroups/manymodelssa/providers/microsoft.insights/components/manymodelssav10130926491',\n",
       " 'identityPrincipalId': '999f751c-ae2e-445e-98b5-454215bbc53a',\n",
       " 'identityTenantId': '72f988bf-86f1-41af-91ab-2d7cd011db47',\n",
       " 'identityType': 'SystemAssigned',\n",
       " 'storageAccount': '/subscriptions/bbd86e7d-3602-4e6d-baa4-40ae2ad9303c/resourcegroups/manymodelssa/providers/microsoft.storage/storageaccounts/manymodelssav16457539585'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws = Workspace(subscription_id=\"bbd86e7d-3602-4e6d-baa4-40ae2ad9303c\", resource_group=\"ManyModelsSA\", workspace_name=\"ManyModelsSAv1\")\n",
    "ws.get_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install azureml-contrib-pipeline-steps\n",
    "#!az ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workspaceblobstore AzureBlob manymodelssav16457539585 azureml-blobstore-77752be6-01b4-4a3e-9d42-03c9c0d6248f\n"
     ]
    }
   ],
   "source": [
    "# ws = Workspace.from_config()\n",
    "\n",
    "# create a new runconfig object\n",
    "run_config = RunConfiguration()\n",
    "run_config.environment.docker.enabled = True\n",
    "run_config.environment.docker.base_image = DEFAULT_CPU_IMAGE\n",
    "run_config.environment.python.conda_dependencies = CondaDependencies.create(conda_packages=['scikit-learn'])\n",
    "\n",
    "#choose a compute target\n",
    "compute = AmlCompute(ws, \"cpu-cluster\")\n",
    "dstore = ws.get_default_datastore()\n",
    "\n",
    "print(dstore.name, dstore.datastore_type, dstore.account_name, dstore.container_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "workercount=3\n",
    "nodecount=1\n",
    "timeout=3000\n",
    "\n",
    "from azureml.pipeline.core import Pipeline, PipelineData\n",
    "\n",
    "dataset1 = Dataset.Tabular.from_delimited_files(path = (dstore, '3modelsdata/Store2_dominicks.csv'))\n",
    "dataset2 = Dataset.Tabular.from_delimited_files(path = (dstore, '3modelsdata/Store5_tropicana.csv'))\n",
    "dataset3 = Dataset.Tabular.from_delimited_files(path = (dstore, '3modelsdata/Store8_minute.maid.csv'))\n",
    "\n",
    "output_dir = PipelineData(name=\"3models\", \n",
    "                          datastore=dstore, \n",
    "                          output_path_on_compute=\"3models/\")\n",
    "\n",
    "from azureml.core import Experiment\n",
    "experiment = Experiment(ws, 'automl-ojforecasting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds1=dataset1.to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       16790.40\n",
       "1       21520.00\n",
       "2       14312.32\n",
       "3        6019.20\n",
       "4        3344.00\n",
       "5       47900.16\n",
       "6       20321.28\n",
       "7       12579.84\n",
       "8       11799.68\n",
       "9        4648.32\n",
       "10      41902.08\n",
       "11       3052.80\n",
       "12      14246.40\n",
       "13      14695.68\n",
       "14      28131.84\n",
       "15      27271.68\n",
       "16      66134.40\n",
       "17      17043.84\n",
       "18      36651.52\n",
       "19       2410.24\n",
       "20       3959.68\n",
       "21       3615.36\n",
       "22     110563.20\n",
       "23       4992.64\n",
       "24      14977.92\n",
       "25      47775.36\n",
       "26       6484.48\n",
       "27       1893.76\n",
       "28      37014.40\n",
       "29      47227.52\n",
       "         ...    \n",
       "80      21565.44\n",
       "81      48946.56\n",
       "82      19968.00\n",
       "83       6495.36\n",
       "84      12976.64\n",
       "85      91393.92\n",
       "86      26355.20\n",
       "87      18212.48\n",
       "88      19200.00\n",
       "89      10032.00\n",
       "90      16332.16\n",
       "91      77009.92\n",
       "92      36526.08\n",
       "93      13777.28\n",
       "94      10233.60\n",
       "95       9999.36\n",
       "96      11849.60\n",
       "97      14067.20\n",
       "98      19313.92\n",
       "99      15466.88\n",
       "100     54069.12\n",
       "101      7514.24\n",
       "102      6556.16\n",
       "103     18800.64\n",
       "104     10738.56\n",
       "105      4280.32\n",
       "106      4146.56\n",
       "107      7363.20\n",
       "108     52543.36\n",
       "109     15724.80\n",
       "Name: Revenue, Length: 110, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds1[ds1.columns[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "from azureml.core.runconfig import CondaDependencies, DEFAULT_CPU_IMAGE\n",
    "\n",
    "batch_conda_deps = CondaDependencies.create(pip_packages=['sklearn'])\n",
    "\n",
    "batch_env = Environment(name=\"manymodels_environment\")\n",
    "batch_env.python.conda_dependencies = batch_conda_deps\n",
    "batch_env.docker.enabled = True\n",
    "batch_env.docker.base_image = DEFAULT_CPU_IMAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.contrib.pipeline.steps import ParallelRunStep, ParallelRunConfig\n",
    "datasetname='store'\n",
    "\n",
    "tags1={}\n",
    "tags1['dataset']=datasetname\n",
    "tags1['nodes']=nodecount\n",
    "tags1['workers-per-node']=workercount\n",
    "tags1['timeout']=timeout\n",
    "\n",
    "parallel_run_config = ParallelRunConfig(\n",
    "    source_directory='./scripts',\n",
    "    entry_script='train.py',\n",
    "    mini_batch_size=\"1\",\n",
    "    run_invocation_timeout=timeout,\n",
    "    error_threshold=10,\n",
    "    output_action=\"summary_only\",\n",
    "    environment=batch_env,\n",
    "    process_count_per_node=workercount,\n",
    "    compute_target=compute,\n",
    "    node_count=nodecount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallelrun_step = ParallelRunStep(\n",
    "    name=\"many-models-training\",\n",
    "    parallel_run_config=parallel_run_config,\n",
    "    inputs=[dataset1.as_named_input(datasetname), dataset2.as_named_input(datasetname), dataset3.as_named_input(datasetname)],\n",
    "    output=output_dir,\n",
    "    models=[],\n",
    "    arguments=[],\n",
    "    allow_reuse=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created step many-models-training [be5bdcc5][9695b249-15a3-473e-bcd3-9baa4b0d9054], (This step will run and generate new outputs)\n",
      "Submitted PipelineRun 6aafdd1d-c357-4aa1-a05c-2b4f448d7e56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - Converting non-string tag to string: (nodes: 1)\n",
      "WARNING - Converting non-string tag to string: (workers-per-node: 3)\n",
      "WARNING - Converting non-string tag to string: (timeout: 3000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Link to Azure Machine Learning studio: https://ml.azure.com/experiments/automl-ojforecasting/runs/6aafdd1d-c357-4aa1-a05c-2b4f448d7e56?wsid=/subscriptions/bbd86e7d-3602-4e6d-baa4-40ae2ad9303c/resourcegroups/ManyModelsSA/workspaces/ManyModelsSAv1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pipeline = Pipeline(workspace=ws, steps=[parallelrun_step])\n",
    "\n",
    "run1 = experiment.submit(pipeline,tags=tags1)\n",
    "#RunDetails(run1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ./code/train.py\n",
    "import pandas as pd\n",
    "import os\n",
    "import uuid\n",
    "\n",
    "\n",
    "from azureml.core.model import Model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "import pickle\n",
    "from azureml.core import Experiment, Workspace, Run\n",
    "from azureml.core import ScriptRunConfig\n",
    "import datetime\n",
    "from entry_script_helper import EntryScriptHelper\n",
    "import logging\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "from joblib import dump, load\n",
    "\n",
    "thisrun = Run.get_context()\n",
    "#childrun=thisrun\n",
    "\n",
    "LOG_NAME = \"user_log\"\n",
    "\n",
    "def init():\n",
    "    EntryScriptHelper().config(LOG_NAME)\n",
    "    logger = logging.getLogger(LOG_NAME)\n",
    "    output_folder = os.path.join(os.environ.get(\"AZ_BATCHAI_INPUT_AZUREML\", \"\"), \"temp/output\")\n",
    "    logger.info(f\"{__file__}.output_folder:{output_folder}\")\n",
    "    logger.info(\"init()\")\n",
    "    return\n",
    "\n",
    "def run(input_data):\n",
    "    logger = logging.getLogger(LOG_NAME)\n",
    "    os.makedirs('./outputs', exist_ok=True)\n",
    "    resultList = []\n",
    "    logger.info('processing all files')\n",
    "    for file in input_data:\n",
    "        u1 = uuid.uuid4()\n",
    "        mname='sklearn_model_'+str(u1)[0:16]\n",
    "        #for w in range(0,1):\n",
    "        with thisrun.child_run(name=mname) as childrun:\n",
    "            for w in range(0,5):\n",
    "                thisrun.log(mname,str(w))       \n",
    "            date1=datetime.datetime.now()\n",
    "            logger.info('starting ('+file+') ' + str(date1))\n",
    "            childrun.log(mname,'starttime-'+str(date1))\n",
    "            # 1.read in the data file\n",
    "            data = pd.read_csv(file,header=None)        \n",
    "            logger.info(data.head())        \n",
    "            # 2. set the data up for training\n",
    "            train,test=train_test_split(data,test_size=0.3)\n",
    "            train_X=train[train.columns[1:116]]\n",
    "            train_y=train[[0]]\n",
    "            test_X=test[train.columns[1:116]]\n",
    "            test_y=train[[0]]\n",
    "            # 3. train a decision tree\n",
    "            dtmodel=DecisionTreeClassifier()\n",
    "            dtmodel.fit(train_X,train_y)\n",
    "            logger.info('done training')\n",
    "            # 4. save the model\n",
    "            logger.info(dtmodel)\n",
    "            logger.info(mname)\n",
    "            with open(mname, 'wb') as file:\n",
    "                joblib.dump(value=dtmodel, filename=os.path.join('./outputs/', mname))\n",
    "            # 5. Register the model\n",
    "            ws1 = childrun.experiment.workspace\n",
    "            try:\n",
    "                childrun.upload_file(mname, os.path.join('./outputs/', mname))\n",
    "            except:\n",
    "                logger.info('dont need to upload')\n",
    "            logger.info('register model, skip the outputs prefix')       \n",
    "            Model.register(workspace=ws1, model_path=os.path.join('./outputs/', mname), model_name=mname, model_framework='sklearn')\n",
    "            #you can return anything you want\n",
    "            date2=datetime.datetime.now()\n",
    "            logger.info('ending ('+str(file)+') ' + str(date2))\n",
    "        \n",
    "            #log some metrics\n",
    "            childrun.log(mname,'endtime-'+str(date2))\n",
    "            childrun.log(mname,'auc-1')\n",
    "        resultList.append(True)\n",
    "    return resultList\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "#cols for IRIS\n",
    "print(data.head())\n",
    "train,test=train_test_split(data,test_size=0.3)\n",
    "train_X=train[[0,1,2,3]]\n",
    "train_y=train[4]\n",
    "test_X=test[[0,1,2,3]]\n",
    "test_y=train[4]\n",
    "dtmodel=DecisionTreeClassifier()\n",
    "dtmodel.fit(train_X,train_y)''' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run= Run(experiment, run_id='1639679a-3711-4840-bad9-067b0c0352f1')\n",
    "run.cancel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from azureml.core.model import Model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "import pickle\n",
    "from azureml.core import Experiment, Workspace, Run\n",
    "from azureml.core import ScriptRunConfig\n",
    "import datetime\n",
    "\n",
    "data = pd.read_csv('./iris0.txt',header=None)\n",
    "print(data.head())\n",
    "print('4')\n",
    "train,test=train_test_split(data,test_size=0.3)\n",
    "print('5')\n",
    "train_X=train[[0,1,2,3]]\n",
    "print('6')\n",
    "train_y=train[4]\n",
    "print('7')\n",
    "test_X=test[[0,1,2,3]]\n",
    "test_y=train[4]\n",
    "print('8')\n",
    "dtmodel=DecisionTreeClassifier()\n",
    "print('9')\n",
    "dtmodel.fit(train_X,train_y)\n",
    "print('10')\n",
    "print(dtmodel)\n",
    "filename = './sklearn_model.pkl'\n",
    "pickle.dump(dtmodel, open(filename, 'wb'))\n",
    "model = Model.register(model_name='sklearn_model_e5ebe522',\n",
    "                   model_path='./sklearn_model.pkl',\n",
    "                   tags = {'area': \"MNIST\", 'type': \"sklearn\"},\n",
    "                   description = \"identify numbers\", workspace=ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/mnt/azmnt/code/Users/buehrer/many_models/code/dota2train.csv',header=None)\n",
    "print(data.head())\n",
    "train,test=train_test_split(data,test_size=0.3)\n",
    "train_X=train[train.columns[1:116]]\n",
    "train_y=train[[0]]\n",
    "test_X=test[train.columns[1:116]]\n",
    "test_y=train[[0]]\n",
    "dtmodel=DecisionTreeClassifier()\n",
    "dtmodel.fit(train_X,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
