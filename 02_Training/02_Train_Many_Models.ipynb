{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Pipeline\n",
    "\n",
    "We are creating a pipeline using ParallelRunStep to forecast orange juice sales. This notebook demonstrates how to create a pipeline that trains and registers 11,973 time-series models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import azureml.core\n",
    "from azureml.core import Workspace, Experiment, Run\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.runconfig import DEFAULT_CPU_IMAGE\n",
    "from azureml.pipeline.core import Pipeline\n",
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "from azureml.widgets import RunDetails\n",
    "from azureml.core import Workspace, Experiment, Datastore\n",
    "from azureml.core.compute import AmlCompute\n",
    "from azureml.core.compute import ComputeTarget\n",
    "from azureml.widgets import RunDetails\n",
    "from azureml.data.data_reference import DataReference\n",
    "from azureml.pipeline.core import Pipeline, PipelineData\n",
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "from azureml.pipeline.core.schedule import ScheduleRecurrence, Schedule\n",
    "from azureml.core.dataset import Dataset\n",
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "from azureml.core import Experiment\n",
    "from azureml.core import Environment\n",
    "from azureml.core.runconfig import CondaDependencies, DEFAULT_CPU_IMAGE\n",
    "from azureml.contrib.pipeline.steps import ParallelRunStep, ParallelRunConfig\n",
    "import datetime\n",
    "\n",
    "print(\"SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example runs on an Azure Machine Learning Notebook VM. If you have already run the Environment Setup and Data Preparation notebooks you are all set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up workspace, datastore, experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ws = Workspace(subscription_id=\"bbd86e7d-3602-4e6d-baa4-40ae2ad9303c\", resource_group=\"ManyModelsSA\", workspace_name=\"ManyModelsSAv1\")\n",
    "\n",
    "# Take a look at Workspace\n",
    "ws.get_details()\n",
    "\n",
    "# choose a datastore\n",
    "dstore = ws.get_default_datastore()\n",
    "scoring_output_dstore = Datastore(ws, 'scoring_output_datastore')\n",
    "train_output_dstore = Datastore(ws, 'training_output_datastore')\n",
    "\n",
    "# choose a experiment\n",
    "experiment = Experiment(ws, 'automl-ojforecasting')\n",
    "print(dstore.name, dstore.datastore_type, dstore.account_name, dstore.container_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the registered dataset from Workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use 11,973 datasets and ParallelRunStep to build 11,973 time-series ARIMA models to predict the quantity of each store brand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each dataset represents a brand's 2 years orange juice sales data that contains 7 columns and 122 rows. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to register the datasets in the Workspace first. The Data Preparation notebook will walk you through this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FileDst10Models = Dataset.get_by_name(ws, name='10modelsfiledataset')\n",
    "FileDst10ModelsInput = FileDst10Models.as_named_input('Train10Models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FileDst1000Models = Dataset.get_by_name(ws, name='1000modelsdataset')\n",
    "FileDst1000ModelsInput = FileDst1000Models.as_named_input('Train1000Models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FileDstAllModels = Dataset.get_by_name(ws, name='AllDataProd')\n",
    "FileDstAllModelsInputs = FileDstAllModels.as_named_input('TrainAllmodels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up environment  for ParallelRunStep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environment defines a collection of resources that we will need to run our pipelines. We configure a reproducible Python environment for machine learning experiments. We are using 2 Python libraries, sklearn and pmdarima. \n",
    "\n",
    "An Environment defines Python packages, environment variables, and Docker settings that are used in machine learning experiments, including in data preparation, training, and deployment to a web service. An Environment is managed and versioned in an Azure Machine Learning Workspace. You can update an existing environment and retrieve a version to reuse. Environments are exclusive to the workspace they are created in and can't be used across different workspaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_conda_deps = CondaDependencies.create(pip_packages=['sklearn','pmdarima', 'azureml-pipeline-core'])\n",
    "batch_env = Environment(name=\"manymodels_environment\")\n",
    "batch_env.python.conda_dependencies = batch_conda_deps\n",
    "batch_env.docker.enabled = True\n",
    "batch_env.docker.base_image = DEFAULT_CPU_IMAGE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up ParallelRunConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train the models, you will need an entry script and a list of dependencies. The entry_script is a user script as a local file path that will be run in parallel on multiple nodes. If source_directly is present, use a relative path. Otherwise, use any path that's accessible on the machine.\n",
    "\n",
    "The <b>entry script</b> accepts requests, tain and register the model, and then returns the results.\n",
    "\n",
    "* <b>init()</b> - Typically this function loads the model into a global object. This function is run only once at the start of batch processing per worker node/process. init method can make use of following environment variables (ParallelRunStep input): \n",
    "\n",
    "                    AZUREML_BI_OUTPUT_PATH â€“ output folder path\n",
    "        \n",
    "* <b>run(mini_batch)</b> - The method to be parallelized. Each invocation will have one minibatch.\n",
    "mini_batch: Batch inference will invoke run method and pass either a list or Pandas DataFrame as an argument to the method. Each entry in mini_batch will be - a filepath if input is a FileDataset, a Pandas DataFrame if input is a TabularDataset.\n",
    "\n",
    "* <b>run method response</b>: run() method should return a Pandas DataFrame or an array. For append_row output_action, these returned elements are appended into the common output file. For summary_only, the contents of the elements are ignored. For all output actions, each returned output element indicates one successful inference of input element in the input mini-batch. User should make sure that enough data is included in inference result to map input to inference. Inference output will be written in output file and not guaranteed to be in order, user should use some key in the output to map it to input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the ParallelRunConfig, you will want to determine the number of workers and nodes appropriate for your use case. The workercount is based off the number of cores of the compute VM. The nodecount will determine the number of master nodes to use. In time-series ARIMA model scenario, increasing the node count will speed up the training process.\n",
    "\n",
    "\n",
    "* <b>node_count</b>: The number of compute nodes to be used for running the user script. We recommend to start with 3 and increase the node_count if the training time is taking too long.\n",
    "\n",
    "* <b>process_count_per_node</b>: Workercount - the number of processes per node. We are using a 8 cores computer cluster therefore we set it to 8.\n",
    "\n",
    "* <b>compute_target</b>: Only AmlCompute is supported. You can change to a different compute cluster if one fails.\n",
    "\n",
    "* <b>run_invocation_timeout</b>: The run() method invocation timeout in seconds. The timeout should be set to be higher than the maximum training time of one model (in seconds), by default it's 60. Since the model that takes the longest to train is about 120 seconds, we set it to be 500 which is greater than 120.   \n",
    "\n",
    "* <b>entry_script</b>: The name of the training script.\n",
    "\n",
    "* <b>source_directory</b>: Paths to folders that contain all files to execute on the compute target (optional).\n",
    "\n",
    "* <b>environment</b>: The Python environment definition. You can configure it to use an existing Python environment or to set up a temporary environment for the experiment. The definition is also responsible for setting the required application dependencies (optional). \n",
    "    \n",
    "* <b>mini_batch_size</b>: The size of the mini-batch passed to a single run() call (optional). \n",
    "\n",
    "    * For FileDataset, it's the number of files with a minimum value of 1. You can combine multiple files into one mini-batch. The default value is 1. In this orange juice sales example, we're using FileDataset and set mini_batch_size to be 1 because we're iterating through a list of FileDataset as our input data.\n",
    "\n",
    "    * For TabularDataset, it's the size of data. Example values are 1024, 1024KB, 10MB, and 1GB. The recommended value is 1MB. The mini-batch from TabularDataset will never cross file boundaries. For example, if you have .csv files with various sizes, the smallest file is 100 KB and the largest is 10 MB. If you set mini_batch_size = 1MB, then files with a size smaller than 1 MB will be treated as one mini-batch. Files with a size larger than 1 MB will be split into multiple mini-batches. \n",
    "\n",
    "* <b>error_threshold</b>: The number of record failures for TabularDataset and file failures for FileDataset that should be ignored during processing. If the error count for the entire input goes above this value, the job will be stopped. The error threshold is for the entire input and not for individual mini-batches sent to the run() method. The range is [-1, int.max]. The -1 part indicates ignoring all failures during processing. You can customize the error threshold based on your fault tolerance. Here we set it to 10, meaning that if 10 or more jobs failed, the job will be stopped and canceled.\n",
    "\n",
    "* <b>output_action</b>: One of the following values indicates how the output will be organized -\n",
    "    * <b>summary_only</b>: The user script will store the output. ParallelRunStep will use the output only for the error threshold calculation. The parallel_run_step.txt will return \n",
    "    * <b>append_row</b>: For all input files, only one file will be created in the output folder to append all outputs separated by line. The file name will be parallel_run_step.txt. We set it to 'append_row' here because we collect the aggregated output file as our training log.\n",
    "    \n",
    "We also added tags to preserve the information about our training cluster's node count, process count per node and dataset name. You can find the 'Tags' column in Azure Machine Learning Studio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[ParallelRunConfig Documentation](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.runconfiguration?view=azure-ml-py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workercount=8\n",
    "nodecount=5\n",
    "timeout=500\n",
    "compute = AmlCompute(ws, \"train-many-model\")\n",
    "\n",
    "datasetname='AllStoresFileDatasets'\n",
    "\n",
    "tags1={}\n",
    "tags1['DatasetName']=datasetname\n",
    "tags1['Nodes']=nodecount\n",
    "tags1['WorkersPerNode']=workercount\n",
    "tags1['Timeout']=timeout\n",
    "\n",
    "parallel_run_config = ParallelRunConfig(\n",
    "    source_directory='./scripts',\n",
    "    entry_script='train.py',\n",
    "    mini_batch_size=\"1\",\n",
    "    run_invocation_timeout=timeout,\n",
    "    error_threshold=10,\n",
    "    output_action=\"append_row\",\n",
    "    environment=batch_env,\n",
    "    process_count_per_node=workercount,\n",
    "    compute_target=compute,\n",
    "    node_count=nodecount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up ParallelRunStep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we set up the output directory and define the Pipeline's output name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = PipelineData(name=\"AllARIMAModels\", \n",
    "                          datastore=dstore, \n",
    "                          output_path_on_compute=\"AllARIMAModels/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We created 4 input arguments that the user can adjust for the forecasting use case.\n",
    "\n",
    "* <b>target_column</b>: The target column is the column name you'd like to predict on.\n",
    "* <b>n_test_periods</b>: The n test periods is the number of periods you'd like to hold off for testing/scoring.\n",
    "* <b>timestamp_column</b>: We set the timestamp column to be the index column for the ARIMA models to train on. \n",
    "* <b>stepwise_training</b>: Stepwise training can be set to 'True' or 'False'. 'False' will conduct a full grid search on each model when training hence will take longer to compelete. 'True' will perform stepwise training and the grid search will be stopped as soon as one of the thresholds are hit, and the best fit model at that time is returned. 'True' will speed up the training process dramatically.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We specify the following parameters:\n",
    "\n",
    "* <b>name</b>: We set a name for our ParallelRunStep.\n",
    "\n",
    "* <b>parallel_run_config</b>: We then pass the previously defined ParallelRunConfig.\n",
    "\n",
    "* <b>inputs</b>: We are going to use the registered FileDataset that we called earlier in the Notebook. _inputs_ points to a registered file dataset in AML studio that points to a path in the blob container. The number of files in that path determines the number of models will be trained in the ParallelRunStep. \n",
    "\n",
    "* <b>output</b>: The output directory we just defined. A PipelineData object that corresponds to the output directory.\n",
    "\n",
    "* <b>models</b>: Zero or more model names already registered in the Azure Machine Learning model registry.\n",
    "\n",
    "* <b>allow_reuse</b>: Whether the step should reuse previous results when run with the same settings/inputs. If this parameter is False, a new run will always be generated for this step during pipeline execution. The default value is True.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[ParallelRunStep Documentation](https://docs.microsoft.com/en-us/python/api/azureml-contrib-pipeline-steps/azureml.contrib.pipeline.steps.parallelrunstep?view=azure-ml-py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallelrun_step = ParallelRunStep(\n",
    "    name=\"many-models-training\",\n",
    "    parallel_run_config=parallel_run_config,\n",
    "    inputs=[FileDstAllModelsInputs],\n",
    "    output=output_dir,\n",
    "    models=[],\n",
    "    arguments=['--target_column','Quantity', '--n_test_periods',6, '--timestamp_column','WeekStarting', '--stepwise_training',True],\n",
    "    allow_reuse=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up RunConfiguration for PythonScriptStep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run configuration represents configuration for experiment runs targeting different compute targets in Azure Machine Learning. The RunConfiguration object encapsulates the information necessary to submit a training run in an experiment. Here we define azureml-pipeline-core and Pandas packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda_run_config = RunConfiguration(framework=\"python\")\n",
    "conda_run_config.target = compute\n",
    "conda_run_config.environment.docker.enabled = True\n",
    "conda_run_config.environment.docker.base_image = DEFAULT_CPU_IMAGE\n",
    "cd = CondaDependencies.create(pip_packages=['azureml-pipeline-core'], conda_packages=['pandas'])\n",
    "conda_run_config.environment.python.conda_dependencies = cd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up PythonScriptStep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then set up a PythonScriptStep to process our log file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We specify the following parameters:\n",
    "\n",
    "* <b>name</b>: We set a name for our PythonScriptStep.\n",
    "\n",
    "* <b>script_name</b>: The name of the log script.\n",
    "\n",
    "* <b>compute_target</b>: Set AML compute target. \n",
    "\n",
    "* <b>runconfig</b>: The RunConfiguration defined during the previous step.\n",
    "\n",
    "* <b>arguments</b>: The arguments you can specify based on your setup.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We created 5 input arguments that the user can adjust for the forecasting use case.\n",
    "\n",
    "* <b>ParallelRunStep_name</b>: The ParallelRunStep name that you defined in the ParallelRunStep.\n",
    "* <b>pipeline_output_name</b>: The ParallelRunStep output directory name. \n",
    "* <b>datastore</b>: The registered datastore name where you put your log file.\n",
    "* <b>experiment</b>: The name of the experiment that ParallelRunStep is running on. \n",
    "* <b>overwrite_logs</b>: 'True' will overwrite the existing log files. 'False' will not overwrite.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "\n",
    "log_python_script_step = PythonScriptStep(name=\"logging\",\n",
    "                        script_name=\"log.py\",\n",
    "                        compute_target=compute,\n",
    "                        source_directory='./scripts',\n",
    "                        runconfig=conda_run_config,\n",
    "                        arguments=['--ParallelRunStep_name','many-models-training','--datastore', 'training_output_datastore', '--experiment', 'automl-ojforecasting', '--overwrite_logs', True, '--pipeline_output_name', 'AllARIMAModels'],\n",
    "                        allow_reuse=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the step sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set up a step sequence to make sure to execute ParallelRunStep and PythonScriptStep execute in the correct order. In this example, we want to run PythonScriptStep after ParallelRunStep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core import StepSequence\n",
    "\n",
    "all_steps = StepSequence(steps=[parallelrun_step, log_python_script_step])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit the pipeline to run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we submit our pipeline to run. The whole training pipeline takes about 1h 16m using a Standard_D13_V2 VM with our current ParallelRunConfig setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from azureml.pipeline.core import Pipeline\n",
    "\n",
    "pipeline = Pipeline(workspace=ws, steps=all_steps)\n",
    "run = experiment.submit(pipeline,tags=tags1)\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can run the folowing command if you'd like to monitor the training process in jupyter notebook. It will stream logs live while training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Succesfully trained, registered and logged 11,973 ARIMA models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Publish the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "published_pipeline = pipeline.publish(name = 'train-many-models',\n",
    "                                     description = 'train 11,973 models with log',\n",
    "                                     version = '1',\n",
    "                                     continue_on_step_failure = True\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ./scripts/train.py\n",
    "\n",
    "from azureml.core.run import Run\n",
    "import pandas as pd\n",
    "import os\n",
    "import uuid\n",
    "import argparse\n",
    "import datetime\n",
    "\n",
    "from azureml.core.model import Model\n",
    "from sklearn import metrics\n",
    "import pickle\n",
    "from azureml.core import Experiment, Workspace, Run\n",
    "from azureml.core import ScriptRunConfig\n",
    "from entry_script_helper import EntryScriptHelper\n",
    "import logging\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "from joblib import dump, load\n",
    "import pmdarima as pm\n",
    "import time\n",
    "from datetime import timedelta\n",
    "\n",
    "thisrun = Run.get_context()\n",
    "\n",
    "LOG_NAME = \"user_log\"\n",
    "\n",
    "print(\"Split the data into train and test\")\n",
    "\n",
    "parser = argparse.ArgumentParser(\"split\")\n",
    "parser.add_argument(\"--target_column\", type=str, help=\"input target column\")\n",
    "parser.add_argument(\"--n_test_periods\", type=int, help=\"input number of test periods\")\n",
    "parser.add_argument(\"--timestamp_column\", type=str, help=\"input timestamp column\")\n",
    "parser.add_argument(\"--stepwise_training\", type=str, help=\"input stepwise training True or False\")\n",
    "\n",
    "args, unknown = parser.parse_known_args()\n",
    "\n",
    "print(\"Argument 1(n_test_periods): %s\" % args.n_test_periods)\n",
    "print(\"Argument 2(target_column): %s\" % args.target_column)\n",
    "print(\"Argument 3(timestamp_column): %s\" % args.timestamp_column)\n",
    "print(\"Argument 4(stepwise_training): %s\" % args.stepwise_training)\n",
    "\n",
    "\n",
    "def init():\n",
    "    EntryScriptHelper().config(LOG_NAME)\n",
    "    logger = logging.getLogger(LOG_NAME)\n",
    "    output_folder = os.path.join(os.environ.get(\"AZ_BATCHAI_INPUT_AZUREML\", \"\"), \"temp/output\")\n",
    "    logger.info(f\"{__file__}.output_folder:{output_folder}\")\n",
    "    logger.info(\"init()\")\n",
    "    return\n",
    "\n",
    "\n",
    "def run(input_data):\n",
    "    # 0. Set up logging\n",
    "    logger = logging.getLogger(LOG_NAME)\n",
    "    os.makedirs('./outputs', exist_ok=True)\n",
    "    logger.info('processing all files')\n",
    "    resultList = []\n",
    "\n",
    "    # 1. Read in the data file\n",
    "    for idx, csv_file_path in enumerate(input_data):       \n",
    "        u1 = uuid.uuid4()\n",
    "        mname='arima'+str(u1)[0:16]\n",
    "        logs = []\n",
    "        date1=datetime.datetime.now()\n",
    "        logger.info('starting ('+csv_file_path+') ' + str(date1))\n",
    "        thisrun.log(mname,'starttime-'+str(date1))\n",
    "            \n",
    "        data = pd.read_csv(csv_file_path,header=0)\n",
    "        logger.info(data.head())\n",
    "\n",
    "        # 2. Split the data into train and test sets based on dates\n",
    "        data = data.set_index(args.timestamp_column)\n",
    "        max_date = datetime.datetime.strptime(data.index.max(),'%Y-%m-%d')\n",
    "        split_date = max_date - timedelta(days=7*args.n_test_periods)\n",
    "        data.index = pd.to_datetime(data.index)\n",
    "        train = data[data.index <= split_date]\n",
    "        test = data[data.index > split_date]\n",
    "\n",
    "        # 3.Train the model\n",
    "        model = pm.auto_arima(train[args.target_column],\n",
    "                  start_p=0,\n",
    "                  start_q=0,\n",
    "                  test='adf', #default stationarity test is kpps\n",
    "                  max_p =3,\n",
    "                  max_d = 2,\n",
    "                  max_q=3,\n",
    "                  m=3, #number of observations per seasonal cycle\n",
    "                  #d=None,\n",
    "                  seasonal=True,\n",
    "                  #trend = None, # adjust this if the series have trend\n",
    "                  #start_P=0,\n",
    "                  #D=0,\n",
    "                  information_criterion = 'aic',\n",
    "                  trace=True, #prints status on the fits\n",
    "                  #error_action='ignore',\n",
    "                  stepwise = args.stepwise_training, # this increments instead of doing a grid search\n",
    "                  suppress_warnings = True,\n",
    "                  out_of_sample_size = 16\n",
    "                 )\n",
    "        model = model.fit(train[args.target_column])\n",
    "        logger.info('done training')\n",
    "\n",
    "        # 4. Save the model\n",
    "        logger.info(model)\n",
    "        logger.info(mname)\n",
    "        with open(mname, 'wb') as file:\n",
    "            joblib.dump(value=model, filename=os.path.join('./outputs/', mname))\n",
    "\n",
    "        # 5. Register the model to the workspace\n",
    "        ws1 = thisrun.experiment.workspace\n",
    "        try:\n",
    "            thisrun.upload_file(mname, os.path.join('./outputs/', mname))\n",
    "        except:\n",
    "            logger.info('dont need to upload')\n",
    "        logger.info('register model, skip the outputs prefix')\n",
    "        model_name = 'arima_'+str(input_data).split('/')[-1][:-6]\n",
    "        print('Trained '+ model_name)\n",
    "        \n",
    "        thisrun.register_model(model_path=mname, model_name=model_name, model_framework='pmdarima',tags={'Store': str(csv_file_path).split('/')[-1][:-4].split('_')[0], 'Brand': str(csv_file_path).split('/')[-1][:-4].split('_')[1], 'ModelType':'ARIMA'}) \n",
    "        print('Registered '+ model_name)\n",
    "        \n",
    "        #6. Log some metrics       \n",
    "        date2=datetime.datetime.now()\n",
    "        logger.info('ending ('+str(csv_file_path)+') ' + str(date2))\n",
    "        \n",
    "        logs.append(str(csv_file_path).split('/')[-1][:-4].split('_')[0])\n",
    "        logs.append(str(csv_file_path).split('/')[-1][:-4].split('_')[1])\n",
    "        logs.append('ARIMA')\n",
    "        logs.append(str(csv_file_path).split('/')[-1][:-4])\n",
    "        logs.append(model_name)\n",
    "        logs.append(str(date1))\n",
    "        logs.append(str(date2))\n",
    "        logs.append(str(date2-date1))\n",
    "        logs.append(idx)\n",
    "        logs.append(len(input_data))\n",
    "        logs.append(thisrun.get_status())\n",
    "\n",
    "        thisrun.log(mname,'endtime-'+str(date2))\n",
    "        thisrun.log(mname,'auc-1')\n",
    "        \n",
    "    resultList.append(logs)\n",
    "    return resultList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ./scripts/log.py\n",
    "\n",
    "import pandas as pd\n",
    "from azureml.core.run import Run\n",
    "from azureml.core import Workspace, Experiment, Datastore\n",
    "import os\n",
    "import datetime\n",
    "from azureml.pipeline.core import PipelineRun\n",
    "import argparse\n",
    "\n",
    "# parse input arguments\n",
    "parser = argparse.ArgumentParser(\"Logging arguments\")\n",
    "\n",
    "parser.add_argument(\"--ParallelRunStep_name\", type=str, help=\"input ParralelRunStep name\")\n",
    "parser.add_argument(\"--datastore\", type=str, help=\"input datastore name\")\n",
    "parser.add_argument(\"--experiment\", type=str, help=\"input experiment name\")\n",
    "parser.add_argument(\"--overwrite_logs\", type=str, help=\"input overwrite logs True or False\")\n",
    "parser.add_argument(\"--pipeline_output_name\", type=str, help=\"input ParralelRunStep output name\")\n",
    "\n",
    "args, unknown = parser.parse_known_args()\n",
    "print(\"Argument1 (ParallelRunStep_name): %s\" % args.ParallelRunStep_name)\n",
    "print(\"Argument2 (datastore): %s\" % args.datastore)\n",
    "print(\"Argument3 (experiment): %s\" % args.experiment)\n",
    "print(\"Argument4 (overwrite_logs): %s\" % args.overwrite_logs)\n",
    "print(\"Argument5 (pipeline_output_name): %s\" % args.pipeline_output_name)\n",
    "\n",
    "# set workspace and experiment \n",
    "thisrun = Run.get_context()\n",
    "ws = thisrun.experiment.workspace\n",
    "experiment = Experiment(ws, args.experiment)\n",
    "\n",
    "# retrieve the log file\n",
    "pipeline_runId = thisrun.get_details()['properties']['azureml.pipelinerunid']\n",
    "pipeline_run = PipelineRun(experiment, pipeline_runId)\n",
    "step_run = pipeline_run.find_step_run(args.ParallelRunStep_name)[0]\n",
    "prediction_output = step_run.get_output_data(args.pipeline_output_name)\n",
    "prediction_output.download(local_path=\"logs\")\n",
    "print('Downloaded the log file of Pipeline Id: '+pipeline_runId)\n",
    "\n",
    "# check the log file path\n",
    "for root, dirs, files in os.walk(\"logs\"):\n",
    "    for file in files:\n",
    "        if file.endswith('parallel_run_step.txt'):\n",
    "            result_file = os.path.join(root,file)\n",
    "            print ('Log file path: ' + result_file)\n",
    "            \n",
    "# read the file and clean up data\n",
    "df_log = pd.read_csv(result_file, converters={0: lambda x: x.strip(\"[\"),10: lambda x: x.strip(\"]\")}, delimiter=\",\", header=None)\n",
    "df_log.columns=['Store','Brand','ModelType','FileName','ModelName','StartTime','EndTime','Duration','Index','BatchSize','Status']\n",
    "df_log['Store'] = df_log['Store'].apply(str).str.replace(\"'\", '')\n",
    "df_log['Brand'] = df_log['Brand'].apply(str).str.replace(\"'\", '')\n",
    "df_log['ModelType'] = df_log['ModelType'].apply(str).str.replace(\"'\", '')\n",
    "df_log['FileName'] = df_log['FileName'].apply(str).str.replace(\"'\", '')\n",
    "df_log['ModelName'] = df_log['ModelName'].apply(str).str.replace(\"'\", '')\n",
    "df_log['StartTime'] = df_log['StartTime'].apply(str).str.replace(\"'\", '')\n",
    "df_log['EndTime'] = df_log['EndTime'].apply(str).str.replace(\"'\", '')\n",
    "df_log['Duration'] = df_log['Duration'].apply(str).str.replace(\"'\", '')\n",
    "df_log['Status'] = df_log['Status'].apply(str).str.replace(\"'\", '')\n",
    "print (df_log.head())\n",
    "print ('Read and cleaned the log file')\n",
    "\n",
    "# save the log file\n",
    "output_path = os.path.join('./logs/', 'training_log')\n",
    "df_log.to_csv(path_or_buf=output_path + '.csv', index = False)\n",
    "print('Saved the training_log.csv')\n",
    "\n",
    "# upload the log file\n",
    "log_dstore = Datastore(ws, args.datastore)\n",
    "log_dstore.upload_files(['./logs/training_log'+'.csv'], target_path='training_log_'+str(datetime.datetime.now().date()), overwrite=args.overwrite_logs, show_progress=True)\n",
    "print('Uploaded the training_log.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
