{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 Data Preperation\n",
    "This solution accelerator uses simulated orange juice sales data to walk you through the process of training many models on Azure Machine Learning. The data used in this example was simulated based on the University of Chicago's Dominick's Finer Foods dataset which featured sales of 3 different orange juice brands for individual stores. The full simulated dataset include 3,991 stores with 3 orange juice brands each thus allowing 11,973 models to be trained to showcase the power of the many models pattern.\n",
    "\n",
    "In this notebook, two datasets will be created: one with all 11,973 files and one with only 10 files that can be used to quickly test and debug. For each dataset, you'll walk you through the process of:\n",
    "\n",
    "1. Downloading the data from Azure Open Datasets\n",
    "2. Uploading the data to Azure Blob Storage\n",
    "3. Registering a File Dataset to the Workspace\n",
    "\n",
    "\n",
    "### Prerequisites \n",
    "At this point, you should have already: \n",
    "1. Created your AML Workspace\n",
    "2. Run the Environment Setup Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0 Connect to your workspace and datastore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.workspace import Workspace\n",
    "ws = Workspace.from_config()\n",
    "datastore = ws.get_default_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0 Download the data from Azure Open Datasets \n",
    "To download the data, import OjSalesSimulated from Azure Open Datasets. Two datasets are being created: one with all 11,973 files and one with 10 files but this can be customized based on your preferences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.opendatasets import OjSalesSimulated\n",
    "\n",
    "# Pull all of the data\n",
    "oj_sales_files = OjSalesSimulated.get_file_dataset()\n",
    "\n",
    "# Pull the first 10 files\n",
    "oj_sales_files_small = OjSalesSimulated.get_file_dataset().take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, create the folders that the data will be downloaded to. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "oj_sales_path = \"oj_sales_data\"\n",
    "if not os.path.exists(oj_sales_path):\n",
    "    os.mkdir(oj_sales_path)\n",
    "    \n",
    "oj_sales_path_small = \"oj_sales_data_small\"\n",
    "if not os.path.exists(oj_sales_path_small):\n",
    "    os.mkdir(oj_sales_path_small)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, download the files to the folder you created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oj_sales_files.download(oj_sales_path, overwrite=True)\n",
    "oj_sales_files_small.download(oj_sales_path_small, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.0 Upload the files to your data store\n",
    "To create the [FileDataset](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.data.file_dataset.filedataset?view=azure-ml-py), you first need to upload the csv files to your blob datastore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_path = 'oj_sales_data' \n",
    "datastore.upload(src_dir = oj_sales_path,\n",
    "                target_path = target_path,\n",
    "                overwrite = True, \n",
    "                show_progress = False)\n",
    "\n",
    "target_path_small = 'oj_sales_data_small'\n",
    "datastore.upload(src_dir = oj_sales_path_small,\n",
    "                target_path = target_path_small,\n",
    "                overwrite = True, \n",
    "                show_progress = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.0 Create the file datasets \n",
    "Now that the files exist in the datastore, [FileDatasets](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.data.file_dataset.filedataset?view=azure-ml-py) can be created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.dataset import Dataset\n",
    "\n",
    "ds_name = 'oj_data'\n",
    "path_on_datastore = datastore.path(target_path + '/')\n",
    "input_ds = Dataset.File.from_files(path=path_on_datastore, validate=False)\n",
    "\n",
    "ds_name_small = 'oj_data_small'\n",
    "path_on_datastore_small = datastore.path(target_path_small + '/')\n",
    "input_ds_small = Dataset.File.from_files(path=path_on_datastore_small, validate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.0 Register the file dataset to the workspace \n",
    "Finally, register the dataset to your workspace so it can be called as an input into the training pipeline in the next notebook. This same dataset will also be used as part of the scoring and forecasting pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "registered_ds = input_ds.register(ws, ds_name, create_new_version=True)\n",
    "\n",
    "registered_ds_small = input_ds_small.register(ws, ds_name_small, create_new_version=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.0 Call the Resigstered dataset *(Optional)*\n",
    "After reigstering the data, it can be easily called using the command below. This is how the datasets will be accessed in future notebooks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oj_ds = Dataset.get_by_name(ws, name = ds_name)\n",
    "oj_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also download the data from the dataset in the future. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oj_ds.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.0 Delete the local files *(Optional)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "shutil.rmtree(oj_sales_path)\n",
    "shutil.rmtree(oj_sales_path_small)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "Now that you have created your dataset, you are ready to move to the Training Notebook to create models. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
